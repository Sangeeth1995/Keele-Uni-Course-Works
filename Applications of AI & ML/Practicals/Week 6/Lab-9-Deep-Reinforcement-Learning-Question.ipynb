{"cells":[{"cell_type":"markdown","metadata":{"id":"KY1Yx_YpKUdl"},"source":["# Course: Application of AI, Data Science and Machine Learning\n","# Lab 9: Deep Reinforcement Learning "]},{"cell_type":"markdown","metadata":{"id":"_VADMMiiKUdq"},"source":["## Objective: Making a cart-pole using reinforcement leanring"]},{"cell_type":"markdown","metadata":{"id":"eAivxesTKUdr"},"source":["# 1. Test Random Environment with OpenAI Gym"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AhUKFNSMKUds"},"outputs":[],"source":["import gym \n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mi0njMyrKUdu","outputId":"a3cd678d-e496-4835-e2c2-fe0e927d00f6"},"outputs":[{"data":{"text/plain":["2"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["env = gym.make('CartPole-v1')\n","states = env.observation_space.shape[0]\n","actions = env.action_space.n\n","actions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ux3xjaUGKUdw","outputId":"54567542-4a2b-443d-c87c-a84b8b6f97c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode:1 Score:12.0\n","Episode:2 Score:29.0\n","Episode:3 Score:29.0\n","Episode:4 Score:13.0\n","Episode:5 Score:12.0\n","Episode:6 Score:18.0\n","Episode:7 Score:21.0\n","Episode:8 Score:22.0\n","Episode:9 Score:25.0\n","Episode:10 Score:10.0\n"]}],"source":["episodes = 10\n","for episode in range(1, episodes+1):\n","    state = env.reset()\n","    done = False\n","    score = 0 \n","    \n","    while not done:\n","        env.render()\n","        action = random.choice([0,1])\n","        n_state, reward, done, info = env.step(action)\n","        score+=reward\n","    print('Episode:{} Score:{}'.format(episode, score))"]},{"cell_type":"markdown","metadata":{"id":"1ZqCI9c_KUdy"},"source":["#  2 Create a Deep Learning Model with Keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKxwHH6KKUdz"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0-1lHl5UKUdz"},"outputs":[],"source":["def build_model(states, actions):\n","    model = Sequential()\n","    model.add(Flatten(input_shape=(1,states)))\n","    model.add(Dense(24, activation='relu'))\n","    model.add(Dense(24, activation='relu'))\n","    model.add(Dense(actions, activation='linear'))\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h7whC7fBKUd1"},"outputs":[],"source":["model = build_model(states, actions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3B7Bk9Z8KUd1","outputId":"93379d3c-a4ad-4c03-b401-ce06daaec8b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           (None, 4)                 0         \n","                                                                 \n"," dense (Dense)               (None, 24)                120       \n","                                                                 \n"," dense_1 (Dense)             (None, 24)                600       \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 50        \n","                                                                 \n","=================================================================\n","Total params: 770\n","Trainable params: 770\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"_XMJoWKYKUd2"},"source":["# 3. Build Agent with Keras-RL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eRHS3p2dKUd2"},"outputs":[],"source":["from rl.agents import DQNAgent\n","from rl.policy import BoltzmannQPolicy\n","from rl.memory import SequentialMemory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0s8MnbLKUd3"},"outputs":[],"source":["def build_agent(model, actions):\n","    policy = BoltzmannQPolicy()\n","    memory = SequentialMemory(limit=50000, window_length=1)\n","    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n","                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n","    return dqn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A3mXg6xpKUd4","outputId":"b19136f2-b3da-45c9-a0ee-2ed1097e4a51"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Training for 50000 steps ...\n","Interval 1 (0 steps performed)\n","\r","    1/10000 [..............................] - ETA: 15:23 - reward: 1.0000"]},{"name":"stderr","output_type":"stream","text":["/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n","/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n","  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"]},{"name":"stdout","output_type":"stream","text":["10000/10000 [==============================] - 104s 10ms/step - reward: 1.0000\n","101 episodes - episode_reward: 98.485 [10.000, 324.000] - loss: 3.038 - mae: 19.919 - mean_q: 40.373\n","\n","Interval 2 (10000 steps performed)\n","10000/10000 [==============================] - 105s 11ms/step - reward: 1.0000\n","46 episodes - episode_reward: 216.109 [165.000, 326.000] - loss: 5.930 - mae: 47.073 - mean_q: 95.085\n","\n","Interval 3 (20000 steps performed)\n","10000/10000 [==============================] - 103s 10ms/step - reward: 1.0000\n","44 episodes - episode_reward: 229.250 [156.000, 443.000] - loss: 3.025 - mae: 49.158 - mean_q: 99.018\n","\n","Interval 4 (30000 steps performed)\n","10000/10000 [==============================] - 125s 12ms/step - reward: 1.0000\n","42 episodes - episode_reward: 235.048 [160.000, 455.000] - loss: 1.808 - mae: 45.069 - mean_q: 90.731\n","\n","Interval 5 (40000 steps performed)\n","10000/10000 [==============================] - 104s 10ms/step - reward: 1.0000\n","done, took 541.869 seconds\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fa571d02be0>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["dqn = build_agent(model, actions)\n","dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n","dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7HEsSihKUd5","outputId":"f1559e04-c65f-4044-d031-a4f7166406b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Testing for 100 episodes ...\n","Episode 1: reward: 196.000, steps: 196\n","Episode 2: reward: 199.000, steps: 199\n","Episode 3: reward: 238.000, steps: 238\n","Episode 4: reward: 224.000, steps: 224\n","Episode 5: reward: 197.000, steps: 197\n","Episode 6: reward: 198.000, steps: 198\n","Episode 7: reward: 234.000, steps: 234\n","Episode 8: reward: 177.000, steps: 177\n","Episode 9: reward: 193.000, steps: 193\n","Episode 10: reward: 254.000, steps: 254\n","Episode 11: reward: 232.000, steps: 232\n","Episode 12: reward: 193.000, steps: 193\n","Episode 13: reward: 201.000, steps: 201\n","Episode 14: reward: 238.000, steps: 238\n","Episode 15: reward: 236.000, steps: 236\n","Episode 16: reward: 202.000, steps: 202\n","Episode 17: reward: 176.000, steps: 176\n","Episode 18: reward: 220.000, steps: 220\n","Episode 19: reward: 209.000, steps: 209\n","Episode 20: reward: 202.000, steps: 202\n","Episode 21: reward: 234.000, steps: 234\n","Episode 22: reward: 198.000, steps: 198\n","Episode 23: reward: 203.000, steps: 203\n","Episode 24: reward: 192.000, steps: 192\n","Episode 25: reward: 226.000, steps: 226\n","Episode 26: reward: 207.000, steps: 207\n","Episode 27: reward: 194.000, steps: 194\n","Episode 28: reward: 226.000, steps: 226\n","Episode 29: reward: 199.000, steps: 199\n","Episode 30: reward: 223.000, steps: 223\n","Episode 31: reward: 243.000, steps: 243\n","Episode 32: reward: 239.000, steps: 239\n","Episode 33: reward: 202.000, steps: 202\n","Episode 34: reward: 178.000, steps: 178\n","Episode 35: reward: 183.000, steps: 183\n","Episode 36: reward: 207.000, steps: 207\n","Episode 37: reward: 207.000, steps: 207\n","Episode 38: reward: 210.000, steps: 210\n","Episode 39: reward: 249.000, steps: 249\n","Episode 40: reward: 169.000, steps: 169\n","Episode 41: reward: 191.000, steps: 191\n","Episode 42: reward: 227.000, steps: 227\n","Episode 43: reward: 204.000, steps: 204\n","Episode 44: reward: 166.000, steps: 166\n","Episode 45: reward: 252.000, steps: 252\n","Episode 46: reward: 258.000, steps: 258\n","Episode 47: reward: 200.000, steps: 200\n","Episode 48: reward: 191.000, steps: 191\n","Episode 49: reward: 190.000, steps: 190\n","Episode 50: reward: 256.000, steps: 256\n","Episode 51: reward: 267.000, steps: 267\n","Episode 52: reward: 243.000, steps: 243\n","Episode 53: reward: 237.000, steps: 237\n","Episode 54: reward: 249.000, steps: 249\n","Episode 55: reward: 211.000, steps: 211\n","Episode 56: reward: 184.000, steps: 184\n","Episode 57: reward: 231.000, steps: 231\n","Episode 58: reward: 204.000, steps: 204\n","Episode 59: reward: 188.000, steps: 188\n","Episode 60: reward: 252.000, steps: 252\n","Episode 61: reward: 212.000, steps: 212\n","Episode 62: reward: 190.000, steps: 190\n","Episode 63: reward: 219.000, steps: 219\n","Episode 64: reward: 229.000, steps: 229\n","Episode 65: reward: 215.000, steps: 215\n","Episode 66: reward: 181.000, steps: 181\n","Episode 67: reward: 230.000, steps: 230\n","Episode 68: reward: 165.000, steps: 165\n","Episode 69: reward: 234.000, steps: 234\n","Episode 70: reward: 227.000, steps: 227\n","Episode 71: reward: 205.000, steps: 205\n","Episode 72: reward: 216.000, steps: 216\n","Episode 73: reward: 212.000, steps: 212\n","Episode 74: reward: 241.000, steps: 241\n","Episode 75: reward: 202.000, steps: 202\n","Episode 76: reward: 195.000, steps: 195\n","Episode 77: reward: 183.000, steps: 183\n","Episode 78: reward: 246.000, steps: 246\n","Episode 79: reward: 211.000, steps: 211\n","Episode 80: reward: 190.000, steps: 190\n","Episode 81: reward: 218.000, steps: 218\n","Episode 82: reward: 239.000, steps: 239\n","Episode 83: reward: 218.000, steps: 218\n","Episode 84: reward: 174.000, steps: 174\n","Episode 85: reward: 219.000, steps: 219\n","Episode 86: reward: 235.000, steps: 235\n","Episode 87: reward: 200.000, steps: 200\n","Episode 88: reward: 198.000, steps: 198\n","Episode 89: reward: 241.000, steps: 241\n","Episode 90: reward: 207.000, steps: 207\n","Episode 91: reward: 230.000, steps: 230\n","Episode 92: reward: 161.000, steps: 161\n","Episode 93: reward: 214.000, steps: 214\n","Episode 94: reward: 260.000, steps: 260\n","Episode 95: reward: 204.000, steps: 204\n","Episode 96: reward: 213.000, steps: 213\n","Episode 97: reward: 200.000, steps: 200\n","Episode 98: reward: 174.000, steps: 174\n","Episode 99: reward: 225.000, steps: 225\n","Episode 100: reward: 195.000, steps: 195\n","212.37\n"]}],"source":["scores = dqn.test(env, nb_episodes=100, visualize=False)\n","print(np.mean(scores.history['episode_reward']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"meT3tBTdKUd6","outputId":"3f02fdcc-67a3-4909-b5d2-c07af2e552b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Testing for 15 episodes ...\n","Episode 1: reward: 227.000, steps: 227\n","Episode 2: reward: 218.000, steps: 218\n","Episode 3: reward: 227.000, steps: 227\n","Episode 4: reward: 185.000, steps: 185\n","Episode 5: reward: 174.000, steps: 174\n","Episode 6: reward: 199.000, steps: 199\n","Episode 7: reward: 231.000, steps: 231\n","Episode 8: reward: 209.000, steps: 209\n","Episode 9: reward: 207.000, steps: 207\n","Episode 10: reward: 244.000, steps: 244\n","Episode 11: reward: 200.000, steps: 200\n","Episode 12: reward: 242.000, steps: 242\n","Episode 13: reward: 236.000, steps: 236\n","Episode 14: reward: 225.000, steps: 225\n","Episode 15: reward: 236.000, steps: 236\n"]}],"source":["_ = dqn.test(env, nb_episodes=15, visualize=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"JTW3OfTLKUd7","outputId":"af1cc9fd-b9a2-408f-cc71-bc034cd35814"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting keras-rl2\n","  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 374 kB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: tensorflow in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from keras-rl2) (2.8.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.44.0)\n","Requirement already satisfied: setuptools in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (52.0.0.post20210125)\n","Requirement already satisfied: libclang>=9.0.1 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (13.0.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (2.8.0.dev2021122109)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (3.19.4)\n","Requirement already satisfied: astunparse>=1.6.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.6.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (3.7.4.3)\n","Requirement already satisfied: gast>=0.2.1 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (0.5.3)\n","Requirement already satisfied: h5py>=2.9.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (2.10.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (2.8.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.1.0)\n","Requirement already satisfied: numpy>=1.20 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.20.1)\n","Requirement already satisfied: absl-py>=0.4.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.0.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (2.8.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (0.24.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.1.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.1 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (0.2.0)\n","Requirement already satisfied: six>=1.12.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorflow->keras-rl2) (1.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.36.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.6.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.25.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.6.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (5.0.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.11.1)\n","Requirement already satisfied: zipp>=0.5 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.4.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2020.12.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.26.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /Users/macbook/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.2.0)\n","Installing collected packages: keras-rl2\n","Successfully installed keras-rl2-1.0.5\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install keras-rl2"]},{"cell_type":"markdown","metadata":{"id":"Rjt3yEIeKUd7"},"source":[" # Credit:https://github.com/nicknochnack/TensorflowKeras-ReinforcementLearning/blob/master/Deep%20Reinforcement%20Learning.ipynb\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-W7Rg5J6KUd7"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Lab-9-Deep-Reinforcement-Learning-Question.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}